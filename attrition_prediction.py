# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JwB53D8wicDLZMZuFcyBjST2G4zYzc_3
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# read the csv file
df = pd.read_csv('Employee-Attrition.csv')
print(df.head())

# split data into X and y
X = df.drop('Attrition', axis=1)
y = df['Attrition']

# remove useless columns
X = X.drop(columns=['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=1)

print(X.columns)

# change text to numbers
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
X['OverTime'] = le.fit_transform(X['OverTime'])
X['Gender'] = le.fit_transform(X['Gender'])

# convert other text columns to numbers
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus'])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

from sklearn.model_selection import train_test_split
#split data 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

# scale the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.linear_model import LogisticRegression
#train the model
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Predict
y_pred = logreg.predict(X_test)

# show results
results = pd.DataFrame({
    'Actual': y_test,
    'Predicted': y_pred
})
print(results)

# get accuracy
from sklearn.metrics import confusion_matrix, accuracy_score
accuracy_score(y_test, y_pred)
print(f"Overall Accuracy: {accuracy_score(y_test, y_pred)}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# draw confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title('Confusion matrix')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.show()

from sklearn.metrics import precision_score,recall_score,f1_score
# check precision, recall, and f1
precision = precision_score(y_test, y_pred)
print(f"Precision Score: {precision:.4f}")

recall = recall_score(y_test, y_pred)
print(f"Recall Score (Sensitivity): {recall:.4f}")


f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.4f}")

from sklearn.metrics import classification_report
# full report
report = classification_report(y_test, y_pred)
print(report)

# get model coefficients
coef = logreg.coef_[0]

# get feature names after encoding
feat_name = ct.get_feature_names_out()

# create table of features and their effect
impDf = pd.DataFrame({'feature': feat_name, 'coefficient': coef})

# sort by biggest effect
impDf['abs_coefficient'] = impDf['coefficient'].abs()
impDf = impDf.sort_values(by='abs_coefficient', ascending=False)

# 5. Plot the top 10 most important features
plt.figure(figsize=(12, 8))

palette = sns.color_palette("viridis", n_colors=10)
sns.barplot(x='coefficient', y='feature', data=impDf.head(10), palette=palette)
plt.title('top 10 most impactful features', fontsize=16)
plt.xlabel('coefficient impact', fontsize=12)
plt.ylabel('feature', fontsize=12)
plt.show()